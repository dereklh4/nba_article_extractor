{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM, Linear Regression, & Logistic Regression Analyses\n",
    "\n",
    "- Let's run SVM, linear regression, and logistic regression on the nba data.\n",
    "- The class label $\\in${name, not a name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import model_selection \n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "fileName = 'I_examples.csv'\n",
    "df = pd.read_csv(fileName)\n",
    "\n",
    "# Get data X (excludes first three columns and class label)\n",
    "X = df.values[:,3:23].astype(float)\n",
    "\n",
    "classLabel = df.values[:, 23].astype(int)\n",
    "\n",
    "# Standardize columns string_length and number_words\n",
    "X1 = preprocessing.scale(X[:,0:2])\n",
    "\n",
    "X_std = np.concatenate((X1,X[:,2:23]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create table to place results in\n",
    "resultMatrix_svm = np.zeros((11,3))\n",
    "resultMatrix_linreg = np.zeros((11,3))\n",
    "resultMatrix_logreg = np.zeros((11,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create folds\n",
    "kfold = model_selection.StratifiedKFold(n_splits=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create classifiers\n",
    "svm = SVC(kernel = 'rbf', random_state = 1, gamma = 0.1, C = 10.0)\n",
    "logreg = LogisticRegression(C = 100.0, random_state = 1)\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2199  2200  2201 ..., 22471 22472 22473] TEST: [   0    1    2 ..., 2408 2412 2419]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [2199 2200 2201 ..., 4898 4901 4903]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [4408 4409 4410 ..., 7403 7420 7428]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [6572 6573 6574 ..., 9533 9540 9542]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [ 8822  8823  8825 ..., 11637 11643 11651]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [11124 11126 11127 ..., 13717 13726 13728]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [13406 13408 13409 ..., 15915 15918 15925]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [15665 15666 15667 ..., 18116 18118 18124]\n",
      "TRAIN: [    0     1     2 ..., 22471 22472 22473] TEST: [17950 17951 17953 ..., 20344 20349 20354]\n",
      "TRAIN: [    0     1     2 ..., 20344 20349 20354] TEST: [20151 20152 20155 ..., 22471 22472 22473]\n"
     ]
    }
   ],
   "source": [
    "currRow = 0\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X_std, classLabel):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    X_train, X_test = X_std[train_idx], X_std[test_idx]\n",
    "    y_train, y_test = classLabel[train_idx], classLabel[test_idx]\n",
    "    \n",
    "    ###\n",
    "    #debug\n",
    "    #vals_yTrain, counts_yTrain = np.unique(y_train, return_counts = True)\n",
    "    #vals_yTest, counts_yTest = np.unique(y_test, return_counts = True)\n",
    "\n",
    "    #print(\"TRAIN LABEL COUNT of 0's:\", counts_yTrain[0])\n",
    "    #print(\"TRAIN LABEL COUNT of 1's:\", counts_yTrain[1])\n",
    "    #print(\"TRAIN LABEL COUNT of 0's:\", counts_yTest[0])\n",
    "    #print(\"TRAIN LABEL COUNT of 1's:\", counts_yTest[1])\n",
    "    ###\n",
    "    \n",
    "    # fit models to data\n",
    "    svm.fit(X_train, y_train)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    linreg.fit(X_train, y_train)\n",
    "    \n",
    "    # predict class labels\n",
    "    y_pred_svm = svm.predict(X_test)\n",
    "    y_pred_logreg = logreg.predict(X_test)\n",
    "    y_pred_linreg = linreg.predict(X_test)\n",
    "    \n",
    "    # apply a threshold (using mean value)\n",
    "    thresh = round(np.mean(y_pred_linreg), 2)\n",
    "    y_pred_linreg = np.where(y_pred_linreg > thresh, 1, 0)\n",
    "    \n",
    "    #compute P, R, and F1 for each classifier\n",
    "    P_svm = precision_score(y_test, y_pred_svm, average = \"macro\")\n",
    "    R_svm = recall_score(y_test, y_pred_svm, average = \"macro\")\n",
    "    F1_svm = f1_score(y_test, y_pred_svm, average = \"macro\")\n",
    "    \n",
    "    P_logreg = precision_score(y_test, y_pred_logreg, average = \"macro\")\n",
    "    R_logreg = recall_score(y_test, y_pred_logreg, average = \"macro\")\n",
    "    F1_logreg = f1_score(y_test, y_pred_logreg, average = \"macro\")\n",
    "  \n",
    "    P_linreg = precision_score(y_test, y_pred_linreg, average = \"macro\")\n",
    "    R_linreg = recall_score(y_test, y_pred_linreg, average = \"macro\")\n",
    "    F1_linreg = f1_score(y_test, y_pred_linreg, average = \"macro\")    \n",
    "\n",
    "    # add to matrix (to return)\n",
    "    currFoldResult = [P_svm, R_svm, F1_svm]\n",
    "    resultMatrix_svm[currRow] = currFoldResult  \n",
    "    \n",
    "    currFoldResult = [P_logreg, R_logreg, F1_logreg]\n",
    "    resultMatrix_logreg[currRow] = currFoldResult\n",
    "    \n",
    "    currFoldResult = [P_linreg, R_linreg, F1_linreg]\n",
    "    resultMatrix_linreg[currRow] = currFoldResult\n",
    "    \n",
    "    currRow = currRow + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate mean and add to resultMatrix\n",
    "meanResult_svm = resultMatrix_svm[0:10,:].mean(0)\n",
    "resultMatrix_svm[10] = meanResult_svm\n",
    "resultMatrix_svm = resultMatrix_svm * 100\n",
    "\n",
    "meanResult_logreg = resultMatrix_logreg[0:10,:].mean(0)\n",
    "resultMatrix_logreg[10] = meanResult_logreg\n",
    "resultMatrix_logreg = resultMatrix_logreg * 100\n",
    "\n",
    "meanResult_linreg = resultMatrix_linreg[0:10,:].mean(0)\n",
    "resultMatrix_linreg[10] = meanResult_linreg\n",
    "resultMatrix_linreg = resultMatrix_linreg * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "np.savetxt(\"Stage1_Results/svmResults.csv\", resultMatrix_svm, delimiter = ',', \n",
    "           header = 'P, R, F1', fmt = '%f', comments = '')\n",
    "\n",
    "np.savetxt(\"Stage1_Results/logRegResults.csv\", resultMatrix_logreg, delimiter = ',', \n",
    "           header = 'P, R, F1', fmt = '%f', comments = '')\n",
    "\n",
    "np.savetxt(\"Stage1_Results/linRegResults.csv\", resultMatrix_linreg, delimiter = ',', \n",
    "           header = 'P, R, F1', fmt = '%f', comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Results\n",
    "\n",
    "- A threshold $T$ was set by using the mean value of the test predictions. Values less than or equal to $T$ are labeled as class 0. Values greater than $T$ are labeled as class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Precision: 74.5872978284\n",
      "Average Recall: 84.7810218049\n",
      "Average F1 score: 75.3998766757\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage Precision: \"+ str(resultMatrix_linreg[10,0])+\n",
    "      \"\\nAverage Recall: \" + str(resultMatrix_linreg[10,1])+\n",
    "      \"\\nAverage F1 score: \"+ str(resultMatrix_linreg[10,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Results\n",
    "\n",
    "- Parameter C was set to 100.0. \n",
    "- I just played around with some values and this gave the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Precision: 88.7815939947\n",
      "Average Recall: 88.7061409214\n",
      "Average F1 score: 88.7086899461\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage Precision: \"+ str(resultMatrix_logreg[10,0])+\n",
    "      \"\\nAverage Recall: \" + str(resultMatrix_logreg[10,1])+\n",
    "      \"\\nAverage F1 score: \"+ str(resultMatrix_logreg[10,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Results\n",
    "\n",
    "- An RBF kernel was used for the SVM. In practice, this seems to be a good starting kernel to choose. The parameters C and gamma were set to the values: C = 10.0, gamma = 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Precision: 90.5415481677\n",
      "Average Recall: 90.0027569383\n",
      "Average F1 score: 90.2495451337\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage Precision: \"+ str(resultMatrix_svm[10,0])+\n",
    "      \"\\nAverage Recall: \" + str(resultMatrix_svm[10,1])+\n",
    "      \"\\nAverage F1 score: \"+ str(resultMatrix_svm[10,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notes:\n",
    "\n",
    "- I create a folder called \"Stage1_Results\" and placed the matrix results there. \n",
    "    - The first ten rows are the P, R, and F1 scores. The last row representes the average score for each P, R, and F1.\n",
    "- SVM outperformed logistic and linear regression, respectively.\n",
    "- Given that recall is high, we should focus on increasing precision.\n",
    "- With precision hovering around 90%, it looks as though the classifier is correctly predicting names as names.\n",
    "- However, there are times where the classifier predicts false positives.\n",
    "    - i.e. incorrectly predicts an instance is a name, when in reality it is not.\n",
    "- So how do we solve increasing P?\n",
    "    - One way would be to set a higher threshold on our predictions. This will make the classifier more conservative, but we risk lowering recall (which we could do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
