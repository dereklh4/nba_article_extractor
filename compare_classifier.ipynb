{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn import model_selection, preprocessing \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Load train and test data from csv to pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('I_examples.csv')\n",
    "test_df = pd.read_csv('J_examples.csv')\n",
    "train_df = train_df.drop(['string', 'doc_id', 'word_loc'], axis =1)\n",
    "test_df = test_df.drop(['string', 'doc_id', 'word_loc'], axis =1)\n",
    "train_feature_data = train_df.drop(['label'], axis = 1)\n",
    "train_feature_data = train_feature_data.values\n",
    "train_label_data = train_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Feature data for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  1,  0, ...,  1,  0,  1],\n",
       "       [15,  2,  0, ...,  1,  0,  0],\n",
       "       [ 8,  1,  0, ...,  1,  1,  0],\n",
       "       ..., \n",
       "       [ 7,  1,  0, ...,  1,  0,  1],\n",
       "       [12,  1,  0, ...,  1,  0,  1],\n",
       "       [ 3,  1,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Label data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>k-fold stratified cross validation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits,random_state=1)\n",
    "skf.get_n_splits(train_feature_data,train_label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Trying out different classifiers such as Decision Tree, RandomForest, SVM, Linear Regression and Logistic Regression\n",
    "<H3>Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Precision: 0.910033464899\n",
      "Average Recall: 0.908526936534\n",
      "Average fscore: 0.90920343611\n"
     ]
    }
   ],
   "source": [
    "decisiontree_classifier = tree.DecisionTreeClassifier()\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "fscore_list = []\n",
    "for train_index, test_index in skf.split(train_feature_data,train_label_data):\n",
    "    decisiontree_classifier.fit(train_feature_data[train_index],train_label_data[train_index])\n",
    "    y_pred = decisiontree_classifier.predict(train_feature_data[test_index])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(train_label_data[test_index],y_pred, average='macro')\n",
    "#     print(precision,recall,fscore)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fscore)\n",
    "print(\"\\n\\nAverage Precision: \"+ str(sum(precision_list)/n_splits)+\n",
    "      \"\\nAverage Recall: \" + str(sum(recall_list)/n_splits)+\n",
    "      \"\\nAverage fscore: \"+ str(sum(fscore_list)/n_splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Precision: 0.916221345677\n",
      "Average Recall: 0.91127355784\n",
      "Average fscore: 0.913627013296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest_classifier = RandomForestClassifier(random_state=1)\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "fscore_list = []\n",
    "for train_index, test_index in skf.split(train_feature_data,train_label_data):\n",
    "    randomforest_classifier.fit(train_feature_data[train_index],train_label_data[train_index])\n",
    "    y_pred = randomforest_classifier.predict(train_feature_data[test_index])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(train_label_data[test_index], y_pred, average='macro')\n",
    "#     print(precision,recall,fscore)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fscore)\n",
    "print(\"\\n\\nAverage Precision: \"+ str(sum(precision_list)/n_splits)+\n",
    "      \"\\nAverage Recall: \" + str(sum(recall_list)/n_splits)+\n",
    "      \"\\nAverage fscore: \"+ str(sum(fscore_list)/n_splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Precision: 0.914892919417\n",
      "Average Recall: 0.906628812171\n",
      "Average fscore: 0.910567297396\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.SVC(kernel = 'rbf', random_state = 1, gamma = 0.1, C = 10.0)\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "fscore_list = []\n",
    "for train_index, test_index in skf.split(train_feature_data,train_label_data):\n",
    "    svm_clf.fit(train_feature_data[train_index],train_label_data[train_index])\n",
    "    y_pred = svm_clf.predict(train_feature_data[test_index])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(train_label_data[test_index], y_pred, average='macro')\n",
    "#     print(precision,recall,fscore)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fscore)\n",
    "print(\"\\n\\nAverage Precision: \"+ str(sum(precision_list)/n_splits)+\n",
    "      \"\\nAverage Recall: \" + str(sum(recall_list)/n_splits)+\n",
    "      \"\\nAverage fscore: \"+ str(sum(fscore_list)/n_splits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726035202936 0.82744436905 0.722863684891\n",
      "0.736470521321 0.839504466197 0.739486983581\n",
      "0.752959277959 0.857688893244 0.7636399234\n",
      "0.75512753546 0.860843355185 0.766343772532\n",
      "0.779802382306 0.881897426426 0.800634280988\n",
      "0.742099436726 0.84205179879 0.752000334784\n",
      "0.75542834933 0.854147573714 0.771080745106\n",
      "0.760445212048 0.865069132073 0.774595966736\n",
      "0.72499571969 0.825666538861 0.722802550928\n",
      "0.735687792292 0.838269056325 0.739280695671\n",
      "\n",
      "\n",
      "Average Precision: 0.746905143007\n",
      "Average Recall: 0.849258260986\n",
      "Average fscore: 0.755272893862\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "fscore_list = []\n",
    "for train_index, test_index in skf.split(train_feature_data,train_label_data):\n",
    "    linreg.fit(train_feature_data[train_index],train_label_data[train_index])\n",
    "    y_pred = linreg.predict(train_feature_data[test_index])\n",
    "    # apply a threshold (using mean value)\n",
    "    thresh = round(np.mean(y_pred), 2)\n",
    "    y_pred = np.where(y_pred > thresh, 1, 0)\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(train_label_data[test_index], y_pred, average='macro')\n",
    "    print(precision,recall,fscore)\n",
    "#     precision_list.append(precision)\n",
    "#     recall_list.append(recall)\n",
    "#     fscore_list.append(fscore)\n",
    "print(\"\\n\\nAverage Precision: \"+ str(sum(precision_list)/n_splits)+\n",
    "      \"\\nAverage Recall: \" + str(sum(recall_list)/n_splits)+\n",
    "      \"\\nAverage fscore: \"+ str(sum(fscore_list)/n_splits))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908688578975 0.873439733428 0.889420232696\n",
      "0.886062428294 0.875669754566 0.880710839955\n",
      "0.894062145289 0.888795369201 0.891389841854\n",
      "0.894978213259 0.90477390048 0.899741007344\n",
      "0.910812168013 0.930336051546 0.920061513753\n",
      "0.892146166081 0.882750764497 0.887324318569\n",
      "0.897563737263 0.886226071465 0.891717468152\n",
      "0.893531116666 0.915526544659 0.903839011311\n",
      "0.881592284933 0.879328060561 0.880452674897\n",
      "0.87209393813 0.864867487118 0.868401972735\n",
      "\n",
      "\n",
      "Average Precision: 0.89315307769\n",
      "Average Recall: 0.890171373752\n",
      "Average fscore: 0.891305888127\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C = 100.0, random_state = 1)\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "fscore_list = []\n",
    "for train_index, test_index in skf.split(train_feature_data,train_label_data):\n",
    "    logreg.fit(train_feature_data[train_index],train_label_data[train_index])\n",
    "    y_pred = logreg.predict(train_feature_data[test_index])\n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(train_label_data[test_index], y_pred, average='macro')\n",
    "#     print(precision,recall,fscore)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    fscore_list.append(fscore)\n",
    "print(\"\\n\\nAverage Precision: \"+ str(sum(precision_list)/n_splits)+\n",
    "      \"\\nAverage Recall: \" + str(sum(recall_list)/n_splits)+\n",
    "      \"\\nAverage fscore: \"+ str(sum(fscore_list)/n_splits))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>From the above results RandomForest Classifier seems to be the best classfier among the tested classifiers\n",
    "<H3>RandomForest Classifier on TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('J_examples.csv')\n",
    "test_df = test_df.drop(['string', 'doc_id', 'word_loc'], axis =1)\n",
    "test_feature_data = test_df.drop(['label'], axis = 1)\n",
    "test_feature_data = test_feature_data.values\n",
    "test_label_data = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Test Set: 0.925820284172\n",
      "Recall on Test Set: 0.923925240472\n",
      "FScore on Test Set: 0.924868230843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest_classifier = RandomForestClassifier(random_state=1)\n",
    "randomforest_classifier.fit(train_feature_data,train_label_data)\n",
    "y_pred = randomforest_classifier.predict(test_feature_data)\n",
    "precision, recall, fscore ,support = precision_recall_fscore_support(test_label_data, y_pred, average='macro')\n",
    "print(\"Precision on Test Set: \"+ str(precision) +\n",
    "      \"\\nRecall on Test Set: \"+ str(recall) +\n",
    "      \"\\nFScore on Test Set: \"+ str(fscore) ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
